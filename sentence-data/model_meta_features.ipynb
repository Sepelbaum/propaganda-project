{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PROPAGANDA CLASSIFICATION MODEL OF META FEATURES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import en_core_web_sm\n",
    "from wordcloud import WordCloud, STOPWORDS\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "import string\n",
    "import spacy\n",
    "from spacy.lang.en.stop_words import STOP_WORDS\n",
    "from spacy.lang.en import English\n",
    "import re\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading in Meta-Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('meta_features.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article_id</th>\n",
       "      <th>propaganda</th>\n",
       "      <th>propaganda_type</th>\n",
       "      <th>text</th>\n",
       "      <th>prop_txt_snippet</th>\n",
       "      <th>sent_#</th>\n",
       "      <th>sentiment_score</th>\n",
       "      <th>abs_sent_score</th>\n",
       "      <th>punct_count</th>\n",
       "      <th>word_count</th>\n",
       "      <th>%adj</th>\n",
       "      <th>%verb</th>\n",
       "      <th>%adv</th>\n",
       "      <th>%noun</th>\n",
       "      <th>avg_word_length</th>\n",
       "      <th>strong_subjectives_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>701225819</td>\n",
       "      <td>non-propaganda</td>\n",
       "      <td>NaN</td>\n",
       "      <td>South Florida Muslim Leader Sofian Zakkout’s D...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.444444</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>701225819</td>\n",
       "      <td>propaganda</td>\n",
       "      <td>Name_Calling,Labeling</td>\n",
       "      <td>David Duke, the white supremacist icon and for...</td>\n",
       "      <td>Grand Wizard of the Ku Klux Klan</td>\n",
       "      <td>2</td>\n",
       "      <td>0.5423</td>\n",
       "      <td>0.5423</td>\n",
       "      <td>4</td>\n",
       "      <td>26</td>\n",
       "      <td>0.020548</td>\n",
       "      <td>0.006849</td>\n",
       "      <td>0.013699</td>\n",
       "      <td>0.006849</td>\n",
       "      <td>4.423077</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>701225819</td>\n",
       "      <td>propaganda</td>\n",
       "      <td>Loaded_Language</td>\n",
       "      <td>However, one individual who represents the Mus...</td>\n",
       "      <td>enamored</td>\n",
       "      <td>3</td>\n",
       "      <td>0.3612</td>\n",
       "      <td>0.3612</td>\n",
       "      <td>4</td>\n",
       "      <td>27</td>\n",
       "      <td>0.017241</td>\n",
       "      <td>0.017241</td>\n",
       "      <td>0.005747</td>\n",
       "      <td>0.022989</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>701225819</td>\n",
       "      <td>non-propaganda</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Last month, once again, Zakkout chose to showc...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>5</td>\n",
       "      <td>22</td>\n",
       "      <td>0.021127</td>\n",
       "      <td>0.021127</td>\n",
       "      <td>0.014085</td>\n",
       "      <td>0.035211</td>\n",
       "      <td>5.045455</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>701225819</td>\n",
       "      <td>non-propaganda</td>\n",
       "      <td>NaN</td>\n",
       "      <td>The postings can be rivaled only by Zakkout’s ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>0.014493</td>\n",
       "      <td>0.043478</td>\n",
       "      <td>0.014493</td>\n",
       "      <td>0.028986</td>\n",
       "      <td>4.636364</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   article_id      propaganda        propaganda_type  \\\n",
       "0   701225819  non-propaganda                    NaN   \n",
       "1   701225819      propaganda  Name_Calling,Labeling   \n",
       "2   701225819      propaganda        Loaded_Language   \n",
       "3   701225819  non-propaganda                    NaN   \n",
       "4   701225819  non-propaganda                    NaN   \n",
       "\n",
       "                                                text  \\\n",
       "0  South Florida Muslim Leader Sofian Zakkout’s D...   \n",
       "1  David Duke, the white supremacist icon and for...   \n",
       "2  However, one individual who represents the Mus...   \n",
       "3  Last month, once again, Zakkout chose to showc...   \n",
       "4  The postings can be rivaled only by Zakkout’s ...   \n",
       "\n",
       "                   prop_txt_snippet  sent_#  sentiment_score  abs_sent_score  \\\n",
       "0                               NaN       1           0.0000          0.0000   \n",
       "1  Grand Wizard of the Ku Klux Klan       2           0.5423          0.5423   \n",
       "2                          enamored       3           0.3612          0.3612   \n",
       "3                               NaN       4           0.0000          0.0000   \n",
       "4                               NaN       5           0.0000          0.0000   \n",
       "\n",
       "   punct_count  word_count      %adj     %verb      %adv     %noun  \\\n",
       "0            0           9  0.000000  0.000000  0.000000  0.000000   \n",
       "1            4          26  0.020548  0.006849  0.013699  0.006849   \n",
       "2            4          27  0.017241  0.017241  0.005747  0.022989   \n",
       "3            5          22  0.021127  0.021127  0.014085  0.035211   \n",
       "4            1          11  0.014493  0.043478  0.014493  0.028986   \n",
       "\n",
       "   avg_word_length  strong_subjectives_count  \n",
       "0         5.444444                         0  \n",
       "1         4.423077                         2  \n",
       "2         5.000000                         0  \n",
       "3         5.045455                         0  \n",
       "4         4.636364                         0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dropping Non-Meta and Deterministic Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_df = df.drop(['propaganda_type','text','prop_txt_snippet','sent_#'], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Previewing Final DataFrame and Missing Values Before Diving In"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article_id</th>\n",
       "      <th>propaganda</th>\n",
       "      <th>sentiment_score</th>\n",
       "      <th>abs_sent_score</th>\n",
       "      <th>punct_count</th>\n",
       "      <th>word_count</th>\n",
       "      <th>%adj</th>\n",
       "      <th>%verb</th>\n",
       "      <th>%adv</th>\n",
       "      <th>%noun</th>\n",
       "      <th>avg_word_length</th>\n",
       "      <th>strong_subjectives_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>701225819</td>\n",
       "      <td>non-propaganda</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.444444</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>701225819</td>\n",
       "      <td>propaganda</td>\n",
       "      <td>0.5423</td>\n",
       "      <td>0.5423</td>\n",
       "      <td>4</td>\n",
       "      <td>26</td>\n",
       "      <td>0.020548</td>\n",
       "      <td>0.006849</td>\n",
       "      <td>0.013699</td>\n",
       "      <td>0.006849</td>\n",
       "      <td>4.423077</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>701225819</td>\n",
       "      <td>propaganda</td>\n",
       "      <td>0.3612</td>\n",
       "      <td>0.3612</td>\n",
       "      <td>4</td>\n",
       "      <td>27</td>\n",
       "      <td>0.017241</td>\n",
       "      <td>0.017241</td>\n",
       "      <td>0.005747</td>\n",
       "      <td>0.022989</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>701225819</td>\n",
       "      <td>non-propaganda</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>5</td>\n",
       "      <td>22</td>\n",
       "      <td>0.021127</td>\n",
       "      <td>0.021127</td>\n",
       "      <td>0.014085</td>\n",
       "      <td>0.035211</td>\n",
       "      <td>5.045455</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>701225819</td>\n",
       "      <td>non-propaganda</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>0.014493</td>\n",
       "      <td>0.043478</td>\n",
       "      <td>0.014493</td>\n",
       "      <td>0.028986</td>\n",
       "      <td>4.636364</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   article_id      propaganda  sentiment_score  abs_sent_score  punct_count  \\\n",
       "0   701225819  non-propaganda           0.0000          0.0000            0   \n",
       "1   701225819      propaganda           0.5423          0.5423            4   \n",
       "2   701225819      propaganda           0.3612          0.3612            4   \n",
       "3   701225819  non-propaganda           0.0000          0.0000            5   \n",
       "4   701225819  non-propaganda           0.0000          0.0000            1   \n",
       "\n",
       "   word_count      %adj     %verb      %adv     %noun  avg_word_length  \\\n",
       "0           9  0.000000  0.000000  0.000000  0.000000         5.444444   \n",
       "1          26  0.020548  0.006849  0.013699  0.006849         4.423077   \n",
       "2          27  0.017241  0.017241  0.005747  0.022989         5.000000   \n",
       "3          22  0.021127  0.021127  0.014085  0.035211         5.045455   \n",
       "4          11  0.014493  0.043478  0.014493  0.028986         4.636364   \n",
       "\n",
       "   strong_subjectives_count  \n",
       "0                         0  \n",
       "1                         2  \n",
       "2                         0  \n",
       "3                         0  \n",
       "4                         0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 15172 entries, 0 to 15171\n",
      "Data columns (total 12 columns):\n",
      "article_id                  15172 non-null int64\n",
      "propaganda                  15172 non-null object\n",
      "sentiment_score             15172 non-null float64\n",
      "abs_sent_score              15172 non-null float64\n",
      "punct_count                 15172 non-null int64\n",
      "word_count                  15172 non-null int64\n",
      "%adj                        15172 non-null float64\n",
      "%verb                       15172 non-null float64\n",
      "%adv                        15172 non-null float64\n",
      "%noun                       15172 non-null float64\n",
      "avg_word_length             15172 non-null float64\n",
      "strong_subjectives_count    15172 non-null int64\n",
      "dtypes: float64(7), int64(4), object(1)\n",
      "memory usage: 1.4+ MB\n"
     ]
    }
   ],
   "source": [
    "meta_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train-Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = meta_df['propaganda']\n",
    "X = meta_df.drop('propaganda', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = [1 if label == 'propaganda' else 0 for label in y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dummy Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.dummy import DummyClassifier\n",
    "\n",
    "dummy_clf = DummyClassifier(strategy='most_frequent')\n",
    "dummy_clf.fit(X_train_scaled, y_train)\n",
    "\n",
    "dummy_preds = dummy_clf.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3510    0]\n",
      " [1497    0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.701     1.000     0.824      3510\n",
      "           1      0.000     0.000     0.000      1497\n",
      "\n",
      "    accuracy                          0.701      5007\n",
      "   macro avg      0.351     0.500     0.412      5007\n",
      "weighted avg      0.491     0.701     0.578      5007\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sashaepelbaum/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# Print the confusion matrix\n",
    "print(sklearn.metrics.confusion_matrix(y_test, dummy_preds))\n",
    "\n",
    "# Print the precision and recall, among other metrics\n",
    "print(sklearn.metrics.classification_report(y_test, dummy_preds, digits=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(y_test, dummy_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import linear_model\n",
    "from sklearn import ensemble\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create logistic regression\n",
    "logistic = linear_model.LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparam_grid_logistic = {'penalty' : ['l1', 'l2'],\n",
    "    'C' : np.logspace(-4, 4, 20),\n",
    "    'solver' : ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga'],\n",
    "    'class_weight': 'balanced'}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create regularization penalty space\n",
    "# penalty = ['l1', 'l2']\n",
    "\n",
    "# # Create regularization hyperparameter distribution using uniform distribution\n",
    "# C = uniform(loc=0, scale=4)\n",
    "\n",
    "# # Create hyperparameter options\n",
    "# hyperparameters = dict(C=C, penalty=penalty)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create randomized search 5-fold cross validation and 100 iterations\n",
    "clf_log = RandomizedSearchCV(logistic, hyperparam_grid_logistic, random_state=1, n_iter=200, cv=5, \n",
    "                         verbose=True, n_jobs=-1, scoring = 'f1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 200 candidates, totalling 1000 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:    3.0s\n",
      "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed:    9.2s\n",
      "[Parallel(n_jobs=-1)]: Done 442 tasks      | elapsed:   19.0s\n",
      "[Parallel(n_jobs=-1)]: Done 792 tasks      | elapsed:   36.6s\n",
      "[Parallel(n_jobs=-1)]: Done 1000 out of 1000 | elapsed:   46.3s finished\n"
     ]
    }
   ],
   "source": [
    "# Fit randomized search\n",
    "best_model_log = clf_log.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Penalty: l2\n",
      "Best C: 10000.0\n",
      "Best solver: sag\n"
     ]
    }
   ],
   "source": [
    "# View best hyperparameters\n",
    "print('Best Penalty:', best_model_log.best_estimator_.get_params()['penalty'])\n",
    "print('Best C:', best_model_log.best_estimator_.get_params()['C'])\n",
    "print('Best solver:', best_model_log.best_estimator_.get_params()['solver'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict target vector\n",
    "log_preds = best_model_log.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3334  176]\n",
      " [1249  248]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.727     0.950     0.824      3510\n",
      "           1      0.585     0.166     0.258      1497\n",
      "\n",
      "    accuracy                          0.715      5007\n",
      "   macro avg      0.656     0.558     0.541      5007\n",
      "weighted avg      0.685     0.715     0.655      5007\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print the confusion matrix\n",
    "print(sklearn.metrics.confusion_matrix(y_test, log_preds))\n",
    "\n",
    "# Print the precision and recall, among other metrics\n",
    "print(sklearn.metrics.classification_report(y_test, log_preds, digits=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5577611062581003"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "roc_auc_score(y_test, log_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "randomforest = ensemble.RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparam_grid_rf=    {'n_estimators' : list(range(10,101,10)),\n",
    "    'max_features' : list(range(6,32,5)),\n",
    "    'criterion':['gini','entropy'],\n",
    "    'class_weight':['balanced']}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_rf = RandomizedSearchCV(randomforest, hyperparam_grid_rf, random_state=1, n_iter=200, cv=5, \n",
    "                         verbose=True, n_jobs=-1, scoring = 'f1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sashaepelbaum/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_search.py:281: UserWarning: The total space of parameters 120 is smaller than n_iter=200. Running 120 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  % (grid_size, self.n_iter, grid_size), UserWarning)\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 120 candidates, totalling 600 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:   29.5s\n",
      "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed:  1.8min\n",
      "[Parallel(n_jobs=-1)]: Done 442 tasks      | elapsed:  4.1min\n",
      "[Parallel(n_jobs=-1)]: Done 600 out of 600 | elapsed:  4.2min finished\n"
     ]
    }
   ],
   "source": [
    "# Fit randomized search\n",
    "best_model_rf = clf_rf.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Penalty: 100\n",
      "Best C: 11\n",
      "Best solver: entropy\n"
     ]
    }
   ],
   "source": [
    "# View best hyperparameters\n",
    "print('Best Penalty:', best_model_rf.best_estimator_.get_params()['n_estimators'])\n",
    "print('Best C:', best_model_rf.best_estimator_.get_params()['max_features'])\n",
    "print('Best solver:', best_model_rf.best_estimator_.get_params()['criterion'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3241  269]\n",
      " [1106  391]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.746     0.923     0.825      3510\n",
      "           1      0.592     0.261     0.363      1497\n",
      "\n",
      "    accuracy                          0.725      5007\n",
      "   macro avg      0.669     0.592     0.594      5007\n",
      "weighted avg      0.700     0.725     0.687      5007\n",
      "\n",
      "0.5922754340590013\n"
     ]
    }
   ],
   "source": [
    "# Predict target vector\n",
    "rf_preds = best_model_rf.predict(X_test_scaled)\n",
    "\n",
    "# Print the confusion matrix\n",
    "print(sklearn.metrics.confusion_matrix(y_test, rf_preds))\n",
    "\n",
    "# Print the precision and recall, among other metrics\n",
    "print(sklearn.metrics.classification_report(y_test, rf_preds, digits=3))\n",
    "\n",
    "print(roc_auc_score(y_test, rf_preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Boosted Decision Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_gboost = GradientBoostingClassifier(n_estimators=100, learning_rate=1.0,\n",
    "    max_depth=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "gboost_model = clf_gboost.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3293  217]\n",
      " [1135  362]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.744     0.938     0.830      3510\n",
      "           1      0.625     0.242     0.349      1497\n",
      "\n",
      "    accuracy                          0.730      5007\n",
      "   macro avg      0.684     0.590     0.589      5007\n",
      "weighted avg      0.708     0.730     0.686      5007\n",
      "\n",
      "0.5899968027222537\n"
     ]
    }
   ],
   "source": [
    "# Predict target vector\n",
    "gboost_preds = gboost_model.predict(X_test_scaled)\n",
    "\n",
    "# Print the confusion matrix\n",
    "print(sklearn.metrics.confusion_matrix(y_test, gboost_preds))\n",
    "\n",
    "# Print the precision and recall, among other metrics\n",
    "print(sklearn.metrics.classification_report(y_test, gboost_preds, digits=3))\n",
    "\n",
    "print(roc_auc_score(y_test, gboost_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparam_grid_gb=    {'n_estimators' : list(range(10,101,10)),\n",
    "#     'max_features' : list(range(6,32,5)),\n",
    "#     'criterion':['gini','entropy'],\n",
    "#     'class_weight':'balanced'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create first network with Keras\n",
    "import keras\n",
    "from keras import layers\n",
    "from keras import callbacks\n",
    "from keras import regularizers\n",
    "from keras import optimizers\n",
    "from keras.layers import Dense, Dropout, Activation\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras import regularizers\n",
    "from keras.optimizers import SGD\n",
    "from keras.layers import Dense\n",
    "from keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_cols = len(X_train.columns)\n",
    "n_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "network1 = Sequential()\n",
    "\n",
    "# Add a dropout layer for input layer\n",
    "network1.add(Dropout(0.2, input_shape=(n_cols,)))\n",
    "# Add fully connected layer with a ReLU activation function\n",
    "network1.add(Dense(units=15, activation='relu'))\n",
    "# Add a dropout layer for previous hidden layer\n",
    "network1.add(Dropout(0.2))\n",
    "# Add fully connected layer with a ReLU activation function and L2 regularization\n",
    "network1.add(Dense(units=15, kernel_regularizer=regularizers.l2(0.01),activation='relu'))\n",
    "\n",
    "\n",
    "network1.add(Dense(1, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "network1.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set callback functions to early stop training and save the best model so far\n",
    "callbacks = [EarlyStopping(monitor='val_loss', patience=20), #if higher loss for 3 consecutive epoch(?), cut-off\n",
    "             ModelCheckpoint(filepath='best_model.h5', monitor='val_loss', save_best_only=True)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 10165 samples, validate on 5007 samples\n",
      "Epoch 1/1000\n",
      " - 2s - loss: 11.0140 - accuracy: 0.2835 - val_loss: 10.7492 - val_accuracy: 0.2990\n",
      "Epoch 2/1000\n",
      " - 2s - loss: 10.9860 - accuracy: 0.2835 - val_loss: 10.7489 - val_accuracy: 0.2990\n",
      "Epoch 3/1000\n",
      " - 2s - loss: 10.9859 - accuracy: 0.2835 - val_loss: 10.7489 - val_accuracy: 0.2990\n",
      "Epoch 4/1000\n",
      " - 2s - loss: 10.9859 - accuracy: 0.2835 - val_loss: 10.7489 - val_accuracy: 0.2990\n",
      "Epoch 5/1000\n",
      " - 2s - loss: 10.9859 - accuracy: 0.2835 - val_loss: 10.7489 - val_accuracy: 0.2990\n",
      "Epoch 6/1000\n",
      " - 2s - loss: 10.9859 - accuracy: 0.2835 - val_loss: 10.7489 - val_accuracy: 0.2990\n",
      "Epoch 7/1000\n",
      " - 2s - loss: 10.9859 - accuracy: 0.2835 - val_loss: 10.7489 - val_accuracy: 0.2990\n",
      "Epoch 8/1000\n",
      " - 2s - loss: 10.9859 - accuracy: 0.2835 - val_loss: 10.7489 - val_accuracy: 0.2990\n",
      "Epoch 9/1000\n",
      " - 2s - loss: 10.9859 - accuracy: 0.2835 - val_loss: 10.7489 - val_accuracy: 0.2990\n",
      "Epoch 10/1000\n",
      " - 2s - loss: 10.9859 - accuracy: 0.2835 - val_loss: 10.7489 - val_accuracy: 0.2990\n",
      "Epoch 11/1000\n",
      " - 2s - loss: 10.9859 - accuracy: 0.2835 - val_loss: 10.7489 - val_accuracy: 0.2990\n",
      "Epoch 12/1000\n",
      " - 2s - loss: 10.9859 - accuracy: 0.2835 - val_loss: 10.7489 - val_accuracy: 0.2990\n",
      "Epoch 13/1000\n",
      " - 2s - loss: 10.9859 - accuracy: 0.2835 - val_loss: 10.7489 - val_accuracy: 0.2990\n",
      "Epoch 14/1000\n",
      " - 2s - loss: 10.9859 - accuracy: 0.2835 - val_loss: 10.7489 - val_accuracy: 0.2990\n",
      "Epoch 15/1000\n",
      " - 2s - loss: 10.9859 - accuracy: 0.2835 - val_loss: 10.7489 - val_accuracy: 0.2990\n",
      "Epoch 16/1000\n",
      " - 2s - loss: 10.9859 - accuracy: 0.2835 - val_loss: 10.7489 - val_accuracy: 0.2990\n",
      "Epoch 17/1000\n",
      " - 2s - loss: 10.9859 - accuracy: 0.2835 - val_loss: 10.7489 - val_accuracy: 0.2990\n",
      "Epoch 18/1000\n",
      " - 2s - loss: 10.9859 - accuracy: 0.2835 - val_loss: 10.7489 - val_accuracy: 0.2990\n",
      "Epoch 19/1000\n",
      " - 2s - loss: 10.9859 - accuracy: 0.2835 - val_loss: 10.7489 - val_accuracy: 0.2990\n",
      "Epoch 20/1000\n",
      " - 2s - loss: 10.9859 - accuracy: 0.2835 - val_loss: 10.7489 - val_accuracy: 0.2990\n",
      "Epoch 21/1000\n",
      " - 2s - loss: 10.9859 - accuracy: 0.2835 - val_loss: 10.7489 - val_accuracy: 0.2990\n",
      "Epoch 22/1000\n",
      " - 2s - loss: 10.9859 - accuracy: 0.2835 - val_loss: 10.7489 - val_accuracy: 0.2990\n"
     ]
    }
   ],
   "source": [
    "# Train neural network\n",
    "history = network1.fit(x = X_train_scaled, # Features\n",
    "                      y = y_train, # Target\n",
    "                      epochs=1000, # Number of epochs\n",
    "                      verbose=2, # Some output\n",
    "                      batch_size=15, # Number of observations per batch\n",
    "                      callbacks=callbacks,\n",
    "                      validation_data=(X_test_scaled, y_test)) # Data for evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
